# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mziH4iR-h0G4eLbKjjfYAQ7eKY5oQJUx
"""

import pandas as pd

df = pd.read_csv("merged_sales_data.csv")
df.head()

df = df.dropna()
df = df[df['Quantity Ordered'].apply(lambda x: str(x).isdigit())]
df = df[df['Price Each'].apply(lambda x: str(x).replace('.', '', 1).isdigit())]

df['Quantity Ordered'] = df['Quantity Ordered'].astype(int)
df['Price Each'] = df['Price Each'].astype(float)
df['Order Date'] = pd.to_datetime(df['Order Date'], errors='coerce')
df = df.dropna(subset=['Order Date'])

df['Total Cost'] = df['Quantity Ordered'] * df['Price Each']
df['Month'] = df['Order Date'].dt.month
df['Hour'] = df['Order Date'].dt.hour
df['Day'] = df['Order Date'].dt.day
df['City'] = df['Purchase Address'].apply(lambda x: x.split(',')[1].strip())

df_numeric = df.drop(columns=['Order ID', 'Order Date', 'Purchase Address', 'Product'])

df_numeric = pd.get_dummies(df_numeric, drop_first=True)
df_numeric.head()

X = df_numeric.drop(columns=['Total Cost'])  # الميزات
y = df_numeric['Total Cost']                 # الهدف

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# تدريب النموذج
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

# التنبؤ
predictions_lr = lr_model.predict(X_test)

# التقييم
mse = mean_squared_error(y_test, predictions_lr)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, predictions_lr)

print(f"Linear Regression - MSE: {mse:.2f}, RMSE: {rmse:.2f}, R2 Score: {r2:.4f}")

from sklearn.tree import DecisionTreeRegressor

# تدريب النموذج
dt_model = DecisionTreeRegressor(random_state=42)
dt_model.fit(X_train, y_train)

# التنبؤ
predictions_dt = dt_model.predict(X_test)

# التقييم
mse = mean_squared_error(y_test, predictions_dt)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, predictions_dt)

print(f"Decision Tree - MSE: {mse:.2f}, RMSE: {rmse:.2f}, R2 Score: {r2:.4f}")

from sklearn.ensemble import RandomForestRegressor

# تدريب النموذج
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# التنبؤ
predictions_rf = rf_model.predict(X_test)

# التقييم
mse = mean_squared_error(y_test, predictions_rf)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, predictions_rf)

print(f"Random Forest - MSE: {mse:.2f}, RMSE: {rmse:.2f}, R2 Score: {r2:.4f}")

from sklearn.neighbors import KNeighborsRegressor

# تدريب النموذج
knn_model = KNeighborsRegressor(n_neighbors=5)
knn_model.fit(X_train, y_train)

# التنبؤ
predictions_knn = knn_model.predict(X_test)

# التقييم
mse = mean_squared_error(y_test, predictions_knn)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, predictions_knn)

print(f"KNN - MSE: {mse:.2f}, RMSE: {rmse:.2f}, R2 Score: {r2:.4f}")

from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# أخذ عينة من بيانات التدريب
X_sample = X_train.sample(n=5000, random_state=42)
y_sample = y_train.loc[X_sample.index]

# تقييس البيانات
scaler = StandardScaler()
X_sample_scaled = scaler.fit_transform(X_sample)
X_test_scaled = scaler.transform(X_test)

# تدريب SVM
svm_model = SVR(kernel='rbf')
svm_model.fit(X_sample_scaled, y_sample)

# التنبؤ
predictions_svm = svm_model.predict(X_test_scaled)

# التقييم
mse = mean_squared_error(y_test, predictions_svm)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, predictions_svm)

print(f"SVM - MSE: {mse:.2f}, RMSE: {rmse:.2f}, R2 Score: {r2:.4f}")

from sklearn.neural_network import MLPRegressor

# إعادة تقييس البيانات (لو السكيلر لسه موجود، نقدر نستخدمه مباشرة)
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# تدريب نموذج ANN
ann_model = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)
ann_model.fit(X_train_scaled, y_train)

# التنبؤ
predictions_ann = ann_model.predict(X_test_scaled)

# التقييم
mse = mean_squared_error(y_test, predictions_ann)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, predictions_ann)

print(f"ANN - MSE: {mse:.2f}, RMSE: {rmse:.2f}, R2 Score: {r2:.4f}")

# إنشاء فئات من القيم العددية
y_binned = pd.cut(y, bins=3, labels=["Low", "Medium", "High"])

# تقسيم البيانات
X_train_nb, X_test_nb, y_train_nb, y_test_nb = train_test_split(X, y_binned, test_size=0.2, random_state=42)

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report

nb_model = GaussianNB()
nb_model.fit(X_train_nb, y_train_nb)

predictions_nb = nb_model.predict(X_test_nb)

accuracy = accuracy_score(y_test_nb, predictions_nb)
print(f"Naive Bayes Accuracy: {accuracy:.4f}")
print(classification_report(y_test_nb, predictions_nb))

# خذي عينة صغيرة من X_train
X_sample = X_train.sample(n=4000, random_state=42)
y_sample = y_train.loc[X_sample.index]

# تقييس العينة
scaler = StandardScaler()
X_sample_scaled = scaler.fit_transform(X_sample)
X_test_scaled = scaler.transform(X_test)

# تدريب SVM على العينة فقط
svm_model = SVR(kernel='rbf')
svm_model.fit(X_sample_scaled, y_sample)

# التنبؤ
predictions_svm = svm_model.predict(X_test_scaled)

# حفظ التوقعات
pd.DataFrame(predictions_svm, columns=["Predicted"]).to_csv("predictions_SVM_model.csv", index=False)

from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler
import pandas as pd

# تقييس البيانات (إذا لم تستخدمي scaler مسبقًا)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# تدريب ANN
ann_model = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)
ann_model.fit(X_train_scaled, y_train)

# التنبؤ
predictions_ann = ann_model.predict(X_test_scaled)

# حفظ التوقعات
pd.DataFrame(predictions_ann, columns=["Predicted"]).to_csv("predictions_ANN_model.csv", index=False)

from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split
import pandas as pd

# تحويل y إلى فئات
y_binned = pd.cut(y, bins=3, labels=["Low", "Medium", "High"])

# تقسيم البيانات
X_train_nb, X_test_nb, y_train_nb, y_test_nb = train_test_split(X, y_binned, test_size=0.2, random_state=42)

# تدريب النموذج
nb_model = GaussianNB()
nb_model.fit(X_train_nb, y_train_nb)

# التنبؤ
predictions_nb = nb_model.predict(X_test_nb)

# حفظ التوقعات
pd.DataFrame(predictions_nb, columns=["Predicted"]).to_csv("predictions_NaiveBayes_model.csv", index=False)

import matplotlib.pyplot as plt

# أسماء النماذج
model_names = [
    "Linear Regression", "Decision Tree", "Random Forest",
    "KNN", "SVM", "ANN", "Naive Bayes"
]

# الدقة أو R2 لكل نموذج (اكتبي القيم الفعلية اللي طلعتيها)
model_scores = [0.9993, 0.9982, 0.9995, 0.9946, 0.9978, 0.9996, 0.9999]  # مثلاً

# الرسم البياني
plt.figure(figsize=(10, 6))
bars = plt.bar(model_names, model_scores)
plt.title("Model Accuracy / R² Comparison")
plt.ylabel("Score")
plt.ylim(0.9, 1.01)
plt.xticks(rotation=30)

# طباعة القيم فوق الأعمدة
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.001, f"{yval:.4f}", ha='center', va='bottom')

plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# تحميل البيانات
df = pd.read_csv("merged_sales_data.csv")

# تنظيف مبدئي
df = df.dropna()
df = df[df['Quantity Ordered'].apply(lambda x: str(x).isdigit())]
df = df[df['Price Each'].apply(lambda x: str(x).replace('.', '', 1).isdigit())]
df['Quantity Ordered'] = df['Quantity Ordered'].astype(int)
df['Price Each'] = df['Price Each'].astype(float)
df['Order Date'] = pd.to_datetime(df['Order Date'], errors='coerce')
df = df.dropna(subset=['Order Date'])

# أعمدة إضافية
df['Total Cost'] = df['Quantity Ordered'] * df['Price Each']
df['Month'] = df['Order Date'].dt.month
df['Hour'] = df['Order Date'].dt.hour
df['City'] = df['Purchase Address'].apply(lambda x: x.split(',')[1].strip())

# ===============================
# 1. إجمالي المبيعات لكل شهر
plt.figure(figsize=(8, 5))
df.groupby('Month')['Total Cost'].sum().plot(kind='bar', color='skyblue')
plt.title('Total Sales per Month')
plt.xlabel('Month')
plt.ylabel('Total Sales')
plt.xticks(rotation=0)
plt.tight_layout()
plt.show()

# ===============================
# 2. المبيعات حسب المدينة
plt.figure(figsize=(8, 5))
df.groupby('City')['Total Cost'].sum().sort_values(ascending=False).plot(kind='bar', color='orange')
plt.title('Total Sales by City')
plt.xlabel('City')
plt.ylabel('Total Sales')
plt.xticks(rotation=30)
plt.tight_layout()
plt.show()

# ===============================
# 3. المنتجات الأعلى مبيعًا
plt.figure(figsize=(10, 5))
df.groupby('Product')['Total Cost'].sum().sort_values(ascending=False).head(10).plot(kind='bar', color='green')
plt.title('Top 10 Products by Total Sales')
plt.xlabel('Product')
plt.ylabel('Total Sales')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# إنشاء العمود Total Price
df['Total Price'] = df['Quantity Ordered'] * df['Price Each']

# Scatter plot
plt.figure(figsize=(10, 6))
plt.scatter(df['Quantity Ordered'], df['Total Price'], alpha=0.5)
plt.title('Scatter Plot: Quantity Ordered vs Total Price')
plt.xlabel('Quantity Ordered')
plt.ylabel('Total Price')
plt.grid(True)
plt.tight_layout()
plt.show()

import seaborn as sns

# استخراج الأعمدة العددية المطلوبة فقط
corr_data = df[['Quantity Ordered', 'Price Each']]
corr_data['Total Price'] = df['Total Price']

# مصفوفة الارتباط
corr_matrix = corr_data.corr()

# Heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Heatmap')
plt.tight_layout()
plt.show()

import seaborn as sns

residuals = y_test - predictions_lr

plt.figure(figsize=(8, 5))
sns.scatterplot(x=predictions_lr, y=residuals)
plt.axhline(0, color='red', linestyle='--')
plt.xlabel("Predicted")
plt.ylabel("Residual")
plt.title("Residual Plot: Linear Regression")
plt.tight_layout()
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns

cm = confusion_matrix(y_test_nb, predictions_nb)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix - Naive Bayes")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()